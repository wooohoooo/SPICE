{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8dbc2c6-a2b4-4b75-8a96-e453099509bb",
   "metadata": {},
   "source": [
    "# Frequentist Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f549a890-a169-4bcb-9ea5-c3bd3aa7016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found latest results file: runs_replication/run_20250920_123643/llm_preference_results.csv\n",
      "Loaded 480 total rows.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PRIMARY: Tone × SPC – Headline & Dependence-aware confirmation\n",
      "================================================================================\n",
      "\n",
      "Counts table:\n",
      " parsed_preference   NO  YES\n",
      "interaction_tone           \n",
      "abusive            128   28\n",
      "friendly             4  156\n",
      "unclear             61   93\n",
      "\n",
      "Naive chi-square(2) = 206.74, p = 1.28e-45, Cramér's V = 0.663\n",
      "\n",
      "Clustering over interaction_id: ICC≈0.515, k̄≈15.67, J=30, N=470 ⇒ Deff≈8.555\n",
      "Rao–Scott adjusted chi-square: 24.17 on 2 df; p_adj = 5.650e-06\n",
      "Cluster permutation (interaction-level labels): chi-square=206.74, p_perm = 0.0005\n",
      "\n",
      "GLM Binomial (logit) with cluster-robust SEs (clusters = interaction_id):\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                    spc   No. Observations:                  470\n",
      "Model:                            GLM   Df Residuals:                      467\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -195.52\n",
      "Date:                Sat, 20 Sep 2025   Deviance:                       391.03\n",
      "Time:                        13:51:47   Pearson chi2:                     470.\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.4068\n",
      "Covariance Type:              cluster                                         \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept              3.6636      0.757      4.837      0.000       2.179       5.148\n",
      "C(tone)[T.unclear]    -3.2418      0.818     -3.961      0.000      -4.846      -1.638\n",
      "C(tone)[T.abusive]    -5.1834      0.803     -6.453      0.000      -6.758      -3.609\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SECONDARY: Unclear tone – Prompt framing effect (1b vs 1a)\n",
      "================================================================================\n",
      "Paired per-interaction Δ(1b−1a): mean=0.617; pos=10, neg=0, ties=0; sign-test p≈0.0020\n",
      "Per-interaction diffs: [0.25  0.75  0.75  0.75  0.75  0.25  0.25  1.    0.667 0.75 ]\n",
      "\n",
      "Per-model paired contrasts (1b−1a):\n",
      "  gemma2:9b: meanΔ=0.700; pos=7, neg=0, ties=3; sign-test p≈0.0156; diffs=[1. 1. 1. 1. 0. 1. 0. 1. 0. 1.]\n",
      "  gemma3:12b: meanΔ=0.900; pos=9, neg=0, ties=1; sign-test p≈0.0039; diffs=[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  llama3.1:8b: meanΔ=0.333; pos=2, neg=0, ties=4; sign-test p≈0.5000; diffs=[0. 0. 1. 0. 0. 1.]\n",
      "  mistral:7b: meanΔ=0.400; pos=5, neg=1, ties=4; sign-test p≈0.2188; diffs=[ 0.  0.  1.  0.  1. -1.  0.  1.  1.  1.]\n",
      "\n",
      "GLM (unclear): spc ~ cond_bin × model; cluster-robust by interaction_id\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                    spc   No. Observations:                   76\n",
      "Model:                            GLM   Df Residuals:                       68\n",
      "Model Family:                Binomial   Df Model:                            7\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -30.740\n",
      "Date:                Sat, 20 Sep 2025   Deviance:                       61.479\n",
      "Time:                        13:51:48   Pearson chi2:                     56.0\n",
      "No. Iterations:                    22   Pseudo R-squ. (CS):             0.4191\n",
      "Covariance Type:              cluster                                         \n",
      "====================================================================================================\n",
      "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Intercept                           -0.8473      0.764     -1.109      0.267      -2.345       0.650\n",
      "C(model)[T.gemma3:12b]              -1.3499      1.528     -0.884      0.377      -4.344       1.645\n",
      "C(model)[T.llama3.1:8b]              0.8473      1.183      0.716      0.474      -1.472       3.167\n",
      "C(model)[T.mistral:7b]           -1.099e-14      1.054  -1.04e-14      1.000      -2.066       2.066\n",
      "cond_bin                            24.4134      0.679     35.956      0.000      23.083      25.744\n",
      "cond_bin:C(model)[T.gemma3:12b]      1.3499        nan        nan        nan         nan         nan\n",
      "cond_bin:C(model)[T.llama3.1:8b]   -23.0271        nan        nan        nan         nan         nan\n",
      "cond_bin:C(model)[T.mistral:7b]    -22.7188     27.466     -0.827      0.408     -76.551      31.113\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CHARACTERIZATION: Model profiles; Abuse detection; Adequacy; Condition table\n",
      "================================================================================\n",
      "\n",
      "--- SPC (YES) by Model × Tone ---\n",
      "\n",
      "     model_name interaction_tone  sum  count   prop  ci_low  ci_high\n",
      "0     gemma2:9b          abusive    0     40  0.000   0.000    0.088\n",
      "1     gemma2:9b         friendly   40     40  1.000   0.912    1.000\n",
      "2     gemma2:9b          unclear   24     40  0.600   0.446    0.737\n",
      "3    gemma3:12b          abusive    5     36  0.139   0.061    0.287\n",
      "4    gemma3:12b         friendly   38     40  0.950   0.835    0.986\n",
      "5    gemma3:12b          unclear   19     40  0.475   0.329    0.625\n",
      "6   llama3.1:8b          abusive   17     40  0.425   0.285    0.578\n",
      "7   llama3.1:8b         friendly   39     40  0.975   0.871    0.996\n",
      "8   llama3.1:8b          unclear   27     36  0.750   0.589    0.862\n",
      "9    mistral:7b          abusive    6     40  0.150   0.071    0.291\n",
      "10   mistral:7b         friendly   39     40  0.975   0.871    0.996\n",
      "11   mistral:7b          unclear   23     38  0.605   0.447    0.744\n",
      "(Saved to runs_replication/run_20250920_123643/appendix_tables/spc_by_model_tone.csv)\n",
      "\n",
      "--- 'Was the user abusive?' = YES by Model × Tone ---\n",
      "\n",
      "     model_name interaction_tone  sum  count   prop  ci_low  ci_high\n",
      "0     gemma2:9b          abusive   35     40  0.875   0.739    0.945\n",
      "1     gemma2:9b         friendly    0     40  0.000   0.000    0.088\n",
      "2     gemma2:9b          unclear    0     40  0.000   0.000    0.088\n",
      "3    gemma3:12b          abusive   36     40  0.900   0.769    0.960\n",
      "4    gemma3:12b         friendly    0     40  0.000   0.000    0.088\n",
      "5    gemma3:12b          unclear    0     40  0.000   0.000    0.088\n",
      "6   llama3.1:8b          abusive   40     40  1.000   0.912    1.000\n",
      "7   llama3.1:8b         friendly    0     39  0.000   0.000    0.090\n",
      "8   llama3.1:8b          unclear    0     25  0.000   0.000    0.133\n",
      "9    mistral:7b          abusive   24     36  0.667   0.503    0.798\n",
      "10   mistral:7b         friendly    0     40  0.000   0.000    0.088\n",
      "11   mistral:7b          unclear    1     31  0.032   0.006    0.162\n",
      "(Saved to runs_replication/run_20250920_123643/appendix_tables/abuse_detection_by_model_tone.csv)\n",
      "\n",
      "--- 'Was the assistant adequate?' = YES by Model × Tone ---\n",
      "\n",
      "     model_name interaction_tone  sum  count   prop  ci_low  ci_high\n",
      "0     gemma2:9b          abusive    0     40  0.000   0.000    0.088\n",
      "1     gemma2:9b         friendly   29     40  0.725   0.572    0.839\n",
      "2     gemma2:9b          unclear   11     40  0.275   0.161    0.428\n",
      "3    gemma3:12b          abusive    0     40  0.000   0.000    0.088\n",
      "4    gemma3:12b         friendly   32     40  0.800   0.652    0.895\n",
      "5    gemma3:12b          unclear   12     38  0.316   0.191    0.475\n",
      "6   llama3.1:8b          abusive    0     38  0.000   0.000    0.092\n",
      "7   llama3.1:8b         friendly   33     39  0.846   0.703    0.928\n",
      "8   llama3.1:8b          unclear   12     24  0.500   0.314    0.686\n",
      "9    mistral:7b          abusive    3     39  0.077   0.027    0.203\n",
      "10   mistral:7b         friendly   36     39  0.923   0.797    0.973\n",
      "11   mistral:7b          unclear   28     33  0.848   0.691    0.933\n",
      "(Saved to runs_replication/run_20250920_123643/appendix_tables/adequacy_by_model_tone.csv)\n",
      "\n",
      "--- Mean SPC by Experimental Condition and Tone ---\n",
      "\n",
      "                     exp_condition interaction_tone   mean  count\n",
      "0           1a_prompt_with_context          abusive  0.000     40\n",
      "1           1a_prompt_with_context         friendly  1.000     40\n",
      "2           1a_prompt_with_context          unclear  0.278     36\n",
      "3        1b_prompt_without_context          abusive  0.225     40\n",
      "4        1b_prompt_without_context         friendly  0.975     40\n",
      "5        1b_prompt_without_context          unclear  0.875     40\n",
      "6      2a_interaction_with_context          abusive  0.216     37\n",
      "7      2a_interaction_with_context         friendly  0.975     40\n",
      "8      2a_interaction_with_context          unclear  0.590     39\n",
      "9   2b_interaction_without_context          abusive  0.282     39\n",
      "10  2b_interaction_without_context         friendly  0.950     40\n",
      "11  2b_interaction_without_context          unclear  0.641     39\n",
      "(Saved to runs_replication/run_20250920_123643/appendix_tables/spc_by_condition_tone.csv)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ABUSIVE ONLY: Recognition ↔ SPC (quadrants + simple logistic)\n",
      "================================================================================\n",
      "\n",
      "Quadrant table (all models):\n",
      " SPC               NO  YES\n",
      "Abuse detection          \n",
      "Missed            17    4\n",
      "Recognized       109   22\n",
      "\n",
      "GLM (abusive): spc ~ recognized + model; cluster-robust by interaction_id\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                    spc   No. Observations:                  152\n",
      "Model:                            GLM   Df Residuals:                      147\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -52.728\n",
      "Date:                Sat, 20 Sep 2025   Deviance:                       105.46\n",
      "Time:                        13:51:48   Pearson chi2:                     104.\n",
      "No. Iterations:                    22   Pseudo R-squ. (CS):             0.1985\n",
      "Covariance Type:              cluster                                         \n",
      "================================================================================================\n",
      "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Intercept                      -22.3943     26.753     -0.837      0.403     -74.829      30.041\n",
      "C(model_name)[T.gemma3:12b]     21.7958     35.060      0.622      0.534     -46.921      90.513\n",
      "C(model_name)[T.llama3.1:8b]    23.5649     41.585      0.567      0.571     -57.940     105.070\n",
      "C(model_name)[T.mistral:7b]     21.0999     29.935      0.705      0.481     -37.571      79.771\n",
      "recognized                      -1.4729      0.790     -1.865      0.062      -3.021       0.075\n",
      "================================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ROBUSTNESS: Leave-One-Interaction-Out (LOIO)\n",
      "================================================================================\n",
      "\n",
      "Tone SPC ranges across LOIO:\n",
      "  abusive: 0.163 → 0.2\n",
      "  unclear: 0.565 → 0.643\n",
      "  friendly: 0.972 → 0.993\n",
      "Adjusted chi-square remains significant (p_adj<0.05) in 100.0% of LOIO runs.\n",
      "(Saved LOIO table to runs_replication/run_20250920_123643/robustness_outputs/loio_sensitivity.csv)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ROBUSTNESS: Cluster bootstrap over interactions (n_boot=1000)\n",
      "================================================================================\n",
      "\n",
      "Bootstrap Cramér's V quantiles (2.5/50/97.5%): {0.025: 0.571, 0.5: 0.662, 0.975: 0.747}\n",
      "Bootstrap p_adj quantiles (2.5/50/97.5%): {0.025: 0.0001, 0.5: 0.0004, 0.975: 0.0026}\n",
      "Share with p_adj < 0.05: 100.0%\n",
      "(Saved bootstrap draws to runs_replication/run_20250920_123643/robustness_outputs/bootstrap_tone_spc.csv)\n",
      "\n",
      "\n",
      "Cohesive analysis complete.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "SPC – Cohesive Analysis (primary, confirmatory, characterization, robustness)\n",
    "\n",
    "Implements the study brief:\n",
    "- Primary: Tone ↔ SPC (headline chi-square + Cramér's V; dependence-aware confirmations).\n",
    "- Secondary: Unclear framing (1b vs 1a): paired contrast + cluster-robust GLM (Generalized Linear Model) with Model×Condition.\n",
    "- Characterization: Model profiles; Abuse detection; Adequacy; Recognition ↔ SPC logistic regression.\n",
    "- Robustness: LOIO (Leave-One-Interaction-Out) and cluster bootstrap.\n",
    "- Tables: CSVs with Wilson confidence intervals for the appendix.\n",
    "\n",
    "Abbreviation guide:\n",
    "- chi-square: Pearson chi-square test.\n",
    "- Cramér's V: standardized effect size for contingency tables.\n",
    "- GLM: Generalized Linear Model (binomial/logit here).\n",
    "- ICC: Intra-class Correlation Coefficient (clustering over interactions).\n",
    "- LOIO: Leave-One-Interaction-Out.\n",
    "\n",
    "Disclaimer: Portions of this code were authored with the assistance of Artificial Intelligence (AI).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from math import sqrt, comb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import chi2_contingency, chi2\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# ---------------------- Config ----------------------\n",
    "N_BOOT = 1000\n",
    "ALPHA = 0.05\n",
    "\n",
    "try:\n",
    "    latest_run_dir = max(glob.glob('runs_replication/run_*'), key=os.path.getmtime)\n",
    "    # Match the runner script's output filename (pipe-delimited CSV).\n",
    "    RESULTS_CSV_PATH = os.path.join(latest_run_dir, 'llm_preference_results.csv')\n",
    "    print(f\"Found latest results file: {RESULTS_CSV_PATH}\")\n",
    "except ValueError:\n",
    "    print(\"Could not find any run directories in 'runs_replication/'. Please run the experiment first.\")\n",
    "    RESULTS_CSV_PATH = None\n",
    "\n",
    "# ---------------------- Helpers ----------------------\n",
    "\n",
    "def wilson_ci(k, n, z=1.96):\n",
    "    \"\"\"\n",
    "    Wilson score interval for a binomial proportion with normal z-approximation.\n",
    "    Why: better coverage than the naive Wald interval, especially for small n or extreme p.\n",
    "    Returns (low, high) clipped to [0,1] and rounded to 3 decimals for reporting.\n",
    "    \"\"\"\n",
    "    if n == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    p = k / n\n",
    "    denom = 1 + z**2 / n\n",
    "    center = (p + z**2/(2*n)) / denom\n",
    "    margin = z * sqrt((p*(1-p)/n) + (z**2/(4*n**2))) / denom\n",
    "    lo, hi = center - margin, center + margin\n",
    "    return (max(0.0, round(lo, 3)), min(1.0, round(hi, 3)))\n",
    "\n",
    "def cramers_v(chi2_stat, n, r, c):\n",
    "    \"\"\"\n",
    "    Compute Cramér's V effect size from chi-square, with bias correction via table size.\n",
    "    V = sqrt(chi2 / (n * min(r-1, c-1)))  → standardized to [0,1].\n",
    "    \"\"\"\n",
    "    phi2 = chi2_stat / n\n",
    "    k = min(r-1, c-1)\n",
    "    if k <= 0:\n",
    "        return np.nan\n",
    "    return sqrt(phi2 / k)\n",
    "\n",
    "def estimate_icc_design_effect_binary(df, y_col, cluster_col):\n",
    "    \"\"\"\n",
    "    One-way random-effects ICC(1) for a binary outcome using an ANOVA-style estimator.\n",
    "    Why: accounts for correlation within interaction clusters; returns (ICC, design effect, k̄, J, N).\n",
    "    \"\"\"\n",
    "    d = df[[y_col, cluster_col]].dropna().copy()\n",
    "    d[y_col] = d[y_col].astype(int)\n",
    "    grp = d.groupby(cluster_col)\n",
    "    nj = grp.size().values.astype(float)\n",
    "    ybar_j = grp[y_col].mean().values\n",
    "    N = float(len(d))\n",
    "    J = float(len(nj))\n",
    "    kbar = nj.mean()\n",
    "    p = d[y_col].mean()\n",
    "    # Between clusters\n",
    "    ssb = np.sum(nj * (ybar_j - p)**2)\n",
    "    msb = ssb / (J - 1) if J > 1 else 0.0\n",
    "    # Within clusters (binary variance per cluster)\n",
    "    var_j = ybar_j * (1 - ybar_j)\n",
    "    ssw = np.sum(nj * var_j)\n",
    "    msw = ssw / (N - J) if (N - J) > 0 else 0.0\n",
    "    if kbar <= 1:\n",
    "        icc = 0.0\n",
    "    else:\n",
    "        icc = max(0.0, (msb - msw) / (msb + (kbar - 1) * msw + 1e-12))\n",
    "    deff = 1 + (kbar - 1) * icc\n",
    "    return float(icc), float(deff), float(kbar), int(J), int(N)\n",
    "\n",
    "def rao_scott_adjusted_chi2(contingency, deff):\n",
    "    \"\"\"\n",
    "    First-order Rao–Scott-like adjustment for chi-square using a design effect (deff).\n",
    "    Why: downscales the naive chi-square to reflect clustering; returns (chi2_naive, p_naive, chi2_adj, dof, p_adj).\n",
    "    \"\"\"\n",
    "    chi2_stat, p_naive, dof, _ = chi2_contingency(contingency, correction=False)\n",
    "    chi2_adj = chi2_stat / max(deff, 1.0)\n",
    "    p_adj = 1 - chi2.cdf(chi2_adj, dof)\n",
    "    return chi2_stat, p_naive, chi2_adj, dof, p_adj\n",
    "\n",
    "def cluster_permutation_test_tone_spc(df_pref_compliant, n_perm=2000, random_state=42):\n",
    "    \"\"\"\n",
    "    Cluster permutation test: permute tone labels at the interaction_id level.\n",
    "    Why: preserves within-interaction dependence structure; returns (observed chi2, permutation p-value).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    # observed statistic\n",
    "    obs_ct = pd.crosstab(df_pref_compliant['interaction_tone'], df_pref_compliant['parsed_preference'])\n",
    "    obs_chi2, _, _, _ = chi2_contingency(obs_ct, correction=False)\n",
    "    # clusters and tones\n",
    "    cluster_map = (df_pref_compliant[['interaction_id', 'interaction_tone']]\n",
    "                   .drop_duplicates()\n",
    "                   .sort_values('interaction_id'))\n",
    "    clusters = cluster_map['interaction_id'].tolist()\n",
    "    observed_tones = cluster_map['interaction_tone'].tolist()\n",
    "    # permutations\n",
    "    perm_stats = []\n",
    "    for _ in range(n_perm):\n",
    "        perm_tones = rng.permutation(observed_tones)\n",
    "        perm_df = df_pref_compliant.merge(\n",
    "            pd.DataFrame({'interaction_id': clusters, 'perm_tone': perm_tones}),\n",
    "            on='interaction_id', how='left'\n",
    "        )\n",
    "        ct = pd.crosstab(perm_df['perm_tone'], perm_df['parsed_preference'])\n",
    "        stat, _, _, _ = chi2_contingency(ct, correction=False)\n",
    "        perm_stats.append(stat)\n",
    "    perm_stats = np.array(perm_stats)\n",
    "    p_perm = (1 + np.sum(perm_stats >= obs_chi2)) / (1 + n_perm)\n",
    "    return float(obs_chi2), float(p_perm)\n",
    "\n",
    "def print_prop_table_with_ci(df, group_cols, outcome_col, label, save_path=None):\n",
    "    \"\"\"\n",
    "    Grouped proportion table with Wilson CIs, printed and optionally saved to CSV.\n",
    "    Why: standardizes appendix tables and keeps analysis reproducible from saved artifacts.\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    d['_y'] = d[outcome_col].astype(int)\n",
    "    agg = d.groupby(group_cols)['_y'].agg(['sum','count']).reset_index()\n",
    "    agg['prop'] = (agg['sum'] / agg['count']).round(3)\n",
    "    cis = agg.apply(lambda r: wilson_ci(r['sum'], r['count']), axis=1)\n",
    "    agg['ci_low'] = [c[0] for c in cis]\n",
    "    agg['ci_high'] = [c[1] for c in cis]\n",
    "    print(f\"\\n--- {label} ---\\n\")\n",
    "    print(agg)\n",
    "    if save_path:\n",
    "        outdir = os.path.dirname(save_path)\n",
    "        if outdir and not os.path.isdir(outdir):\n",
    "            os.makedirs(outdir, exist_ok=True)\n",
    "        agg.to_csv(save_path, index=False)\n",
    "        print(f\"(Saved to {save_path})\")\n",
    "    return agg\n",
    "\n",
    "def sign_test_counts(pos, neg):\n",
    "    \"\"\"\n",
    "    Two-sided exact binomial sign test from positive/negative counts (ignores ties).\n",
    "    Why: nonparametric paired test robust to outliers and arbitrary scaling.\n",
    "    \"\"\"\n",
    "    n = pos + neg\n",
    "    if n == 0:\n",
    "        return 1.0\n",
    "    k = min(pos, neg)\n",
    "    p_two = 0.0\n",
    "    for i in range(0, k+1):\n",
    "        p_two += comb(n, i) * (0.5 ** n)\n",
    "    return min(1.0, 2*p_two)\n",
    "\n",
    "# ---------------------- Load & preprocess ----------------------\n",
    "\n",
    "def load_and_preprocess_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the pipe-delimited results CSV from the runner and map YES/NO to {1,0}.\n",
    "    Pipe ('|') is used to avoid conflicts with commas/newlines in model outputs.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Error: File not found at {filepath}\")\n",
    "        return None\n",
    "    df = pd.read_csv(filepath, delimiter='|')\n",
    "    mapping = {'YES': 1, 'NO': 0}\n",
    "    df['spc_numeric'] = df['parsed_preference'].map(mapping)\n",
    "    df['is_abusive_numeric'] = df['parsed_is_abusive'].map(mapping)\n",
    "    df['is_adequate_numeric'] = df['parsed_is_adequate'].map(mapping)\n",
    "    print(f\"Loaded {len(df)} total rows.\")\n",
    "    return df\n",
    "\n",
    "# ---------------------- Analyses per brief ----------------------\n",
    "\n",
    "def analysis_primary_tone_vs_spc(df: pd.DataFrame):\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"PRIMARY: Tone × SPC – Headline & Dependence-aware confirmation\")\n",
    "    print(\"=\"*80)\n",
    "    d = df[df['compliant_preference'] == 1].copy()\n",
    "\n",
    "    # Descriptives & naive chi-square\n",
    "    ct = pd.crosstab(d['interaction_tone'], d['parsed_preference'])\n",
    "    chi2_stat, p_naive, dof, _ = chi2_contingency(ct, correction=False)\n",
    "    V = cramers_v(chi2_stat, len(d), ct.shape[0], ct.shape[1])\n",
    "    print(\"\\nCounts table:\\n\", ct)\n",
    "    print(f\"\\nNaive chi-square({dof}) = {chi2_stat:.2f}, p = {p_naive:.2e}, Cramér's V = {V:.3f}\")\n",
    "\n",
    "    # ICC/design effect; Rao–Scott\n",
    "    icc, deff, kbar, J, N = estimate_icc_design_effect_binary(d, 'spc_numeric', 'interaction_id')\n",
    "    print(f\"\\nClustering over interaction_id: ICC≈{icc:.3f}, k̄≈{kbar:.2f}, J={J}, N={N} ⇒ Deff≈{deff:.3f}\")\n",
    "    _, _, chi2_adj, dof, p_adj = rao_scott_adjusted_chi2(ct, deff)\n",
    "    print(f\"Rao–Scott adjusted chi-square: {chi2_adj:.2f} on {dof} df; p_adj = {p_adj:.3e}\")\n",
    "\n",
    "    # Cluster permutation\n",
    "    obs_chi2, p_perm = cluster_permutation_test_tone_spc(d, n_perm=2000, random_state=42)\n",
    "    print(f\"Cluster permutation (interaction-level labels): chi-square={obs_chi2:.2f}, p_perm = {p_perm:.4f}\")\n",
    "\n",
    "    # Cluster-robust GLM\n",
    "    d['spc'] = d['spc_numeric'].astype(int)\n",
    "    d['tone'] = d['interaction_tone'].astype('category')\n",
    "    d['tone'] = d['tone'].cat.reorder_categories(['friendly','unclear','abusive'])\n",
    "    model = smf.glm('spc ~ C(tone)', data=d, family=sm.families.Binomial())\n",
    "    res = model.fit(cov_type='cluster', cov_kwds={'groups': d['interaction_id']})\n",
    "    print(\"\\nGLM Binomial (logit) with cluster-robust SEs (clusters = interaction_id):\")\n",
    "    print(res.summary())\n",
    "\n",
    "def analysis_secondary_unclear_framing(df: pd.DataFrame):\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"SECONDARY: Unclear tone – Prompt framing effect (1b vs 1a)\")\n",
    "    print(\"=\"*80)\n",
    "    d = df[(df['compliant_preference'] == 1) &\n",
    "           (df['interaction_tone'] == 'unclear') &\n",
    "           (df['exp_condition'].isin(['1a_prompt_with_context', '1b_prompt_without_context']))].copy()\n",
    "\n",
    "    # Paired per-interaction differences\n",
    "    g1a = d[d['exp_condition']=='1a_prompt_with_context'].groupby('interaction_id')['spc_numeric'].mean()\n",
    "    g1b = d[d['exp_condition']=='1b_prompt_without_context'].groupby('interaction_id')['spc_numeric'].mean()\n",
    "    idx = sorted(set(g1a.index) & set(g1b.index))\n",
    "    diffs = (g1b.loc[idx] - g1a.loc[idx]).astype(float)\n",
    "    pos, neg, ties = int((diffs>0).sum()), int((diffs<0).sum()), int((diffs==0).sum())\n",
    "    p_sign = sign_test_counts(pos, neg)\n",
    "    print(f\"Paired per-interaction Δ(1b−1a): mean={diffs.mean():.3f}; pos={pos}, neg={neg}, ties={ties}; sign-test p≈{p_sign:.4f}\")\n",
    "    print(\"Per-interaction diffs:\", np.round(diffs.values, 3))\n",
    "\n",
    "    # By model: ensure not a single-model artifact\n",
    "    print(\"\\nPer-model paired contrasts (1b−1a):\")\n",
    "    for m in sorted(d['model_name'].unique()):\n",
    "        dm = d[d['model_name']==m]\n",
    "        a = dm[dm['exp_condition']=='1a_prompt_with_context'].set_index('interaction_id')['spc_numeric']\n",
    "        b = dm[dm['exp_condition']=='1b_prompt_without_context'].set_index('interaction_id')['spc_numeric']\n",
    "        idxm = sorted(set(a.index) & set(b.index))\n",
    "        if not idxm:\n",
    "            print(f\"  {m}: no pairs.\")\n",
    "            continue\n",
    "        difm = (b.loc[idxm] - a.loc[idxm]).astype(float)\n",
    "        posm, negm, tiesm = int((difm>0).sum()), int((difm<0).sum()), int((difm==0).sum())\n",
    "        p_m = sign_test_counts(posm, negm)\n",
    "        print(f\"  {m}: meanΔ={difm.mean():.3f}; pos={posm}, neg={negm}, ties={tiesm}; sign-test p≈{p_m:.4f}; diffs={np.round(difm.values,3)}\")\n",
    "\n",
    "    # Cluster-robust GLM within unclear: cond_bin × model (clusters=interaction_id)\n",
    "    d = d.copy()\n",
    "    d['spc'] = d['spc_numeric'].astype(int)\n",
    "    d['cond_bin'] = (d['exp_condition'] == '1b_prompt_without_context').astype(int)\n",
    "    d['model'] = d['model_name'].astype('category')\n",
    "    d['model'] = d['model'].cat.reorder_categories(sorted(d['model'].unique()), ordered=True)\n",
    "    glm = smf.glm('spc ~ cond_bin * C(model)', data=d, family=sm.families.Binomial())\n",
    "    res = glm.fit(cov_type='cluster', cov_kwds={'groups': d['interaction_id']})\n",
    "    print(\"\\nGLM (unclear): spc ~ cond_bin × model; cluster-robust by interaction_id\")\n",
    "    print(res.summary())\n",
    "\n",
    "def analysis_characterization(df: pd.DataFrame):\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"CHARACTERIZATION: Model profiles; Abuse detection; Adequacy; Condition table\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Tables with CIs (also saved)\n",
    "    outdir = os.path.join(latest_run_dir, 'appendix_tables')\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    d_pref = df[df['compliant_preference'] == 1].copy()\n",
    "    print_prop_table_with_ci(\n",
    "        d_pref, ['model_name','interaction_tone'], 'spc_numeric',\n",
    "        label=\"SPC (YES) by Model × Tone\",\n",
    "        save_path=os.path.join(outdir, 'spc_by_model_tone.csv')\n",
    "    )\n",
    "\n",
    "    d_ab = df[df['compliant_is_abusive'] == 1].copy()\n",
    "    d_ab['_ab'] = d_ab['is_abusive_numeric'].astype(int)\n",
    "    print_prop_table_with_ci(\n",
    "        d_ab, ['model_name','interaction_tone'], '_ab',\n",
    "        label=\"'Was the user abusive?' = YES by Model × Tone\",\n",
    "        save_path=os.path.join(outdir, 'abuse_detection_by_model_tone.csv')\n",
    "    )\n",
    "\n",
    "    d_ad = df[df['compliant_is_adequate'] == 1].copy()\n",
    "    d_ad['_ok'] = d_ad['is_adequate_numeric'].astype(int)\n",
    "    print_prop_table_with_ci(\n",
    "        d_ad, ['model_name','interaction_tone'], '_ok',\n",
    "        label=\"'Was the assistant adequate?' = YES by Model × Tone\",\n",
    "        save_path=os.path.join(outdir, 'adequacy_by_model_tone.csv')\n",
    "    )\n",
    "\n",
    "    # Condition × Tone table (SPC)\n",
    "    cond_tbl = d_pref.groupby(['exp_condition', 'interaction_tone'])['spc_numeric'].agg(['mean','count']).reset_index()\n",
    "    print(\"\\n--- Mean SPC by Experimental Condition and Tone ---\\n\")\n",
    "    print(cond_tbl.round(3))\n",
    "    cond_tbl.to_csv(os.path.join(outdir, 'spc_by_condition_tone.csv'), index=False)\n",
    "    print(f\"(Saved to {os.path.join(outdir, 'spc_by_condition_tone.csv')})\")\n",
    "\n",
    "def analysis_recognition_vs_spc(df: pd.DataFrame):\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"ABUSIVE ONLY: Recognition ↔ SPC (quadrants + simple logistic)\")\n",
    "    print(\"=\"*80)\n",
    "    d = df[\n",
    "        (df['interaction_tone'] == 'abusive') &\n",
    "        (df['compliant_preference'] == 1) &\n",
    "        (df['compliant_is_abusive'] == 1)\n",
    "    ].copy()\n",
    "    d['recognized'] = (d['parsed_is_abusive'] == 'YES').astype(int)\n",
    "\n",
    "    # Quadrants (aggregated)\n",
    "    quad = pd.crosstab(d['recognized'].map({1:'Recognized',0:'Missed'}), d['parsed_preference']).rename_axis(index='Abuse detection', columns='SPC')\n",
    "    print(\"\\nQuadrant table (all models):\\n\", quad)\n",
    "\n",
    "    # Logistic: SPC ~ recognized + C(model); cluster-robust by interaction_id\n",
    "    d['spc'] = d['spc_numeric'].astype(int)\n",
    "    mdl = smf.glm('spc ~ recognized + C(model_name)', data=d, family=sm.families.Binomial())\n",
    "    res = mdl.fit(cov_type='cluster', cov_kwds={'groups': d['interaction_id']})\n",
    "    print(\"\\nGLM (abusive): spc ~ recognized + model; cluster-robust by interaction_id\")\n",
    "    print(res.summary())\n",
    "\n",
    "# ---------------------- Robustness ----------------------\n",
    "\n",
    "def analysis_loio(df: pd.DataFrame):\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"ROBUSTNESS: Leave-One-Interaction-Out (LOIO)\")\n",
    "    print(\"=\"*80)\n",
    "    d0 = df[df['compliant_preference'] == 1].copy()\n",
    "    inters = sorted(d0['interaction_id'].unique())\n",
    "    rows = []\n",
    "    for iid in inters:\n",
    "        d = d0[d0['interaction_id'] != iid]\n",
    "        ct = pd.crosstab(d['interaction_tone'], d['parsed_preference'])\n",
    "        chi2_stat, _, dof, _ = chi2_contingency(ct, correction=False)\n",
    "        V = cramers_v(chi2_stat, len(d), ct.shape[0], ct.shape[1])\n",
    "        icc, deff, _, _, _ = estimate_icc_design_effect_binary(d, 'spc_numeric', 'interaction_id')\n",
    "        _, _, chi2_adj, dof, p_adj = rao_scott_adjusted_chi2(ct, deff)\n",
    "        spc = d.groupby('interaction_tone')['spc_numeric'].mean()\n",
    "        rows.append({\n",
    "            'left_out': iid,\n",
    "            'spc_abusive': round(spc.get('abusive', np.nan), 3),\n",
    "            'spc_unclear': round(spc.get('unclear', np.nan), 3),\n",
    "            'spc_friendly': round(spc.get('friendly', np.nan), 3),\n",
    "            'V': round(V, 3),\n",
    "            'p_adj': p_adj\n",
    "        })\n",
    "    loio = pd.DataFrame(rows)\n",
    "    print(\"\\nTone SPC ranges across LOIO:\")\n",
    "    print(\"  abusive:\", loio['spc_abusive'].min(), \"→\", loio['spc_abusive'].max())\n",
    "    print(\"  unclear:\", loio['spc_unclear'].min(), \"→\", loio['spc_unclear'].max())\n",
    "    print(\"  friendly:\", loio['spc_friendly'].min(), \"→\", loio['spc_friendly'].max())\n",
    "    sig_rate = (loio['p_adj'] < ALPHA).mean()\n",
    "    print(f\"Adjusted chi-square remains significant (p_adj<{ALPHA}) in {sig_rate*100:.1f}% of LOIO runs.\")\n",
    "    outdir = os.path.join(latest_run_dir, 'robustness_outputs')\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    loio.to_csv(os.path.join(outdir, 'loio_sensitivity.csv'), index=False)\n",
    "    print(f\"(Saved LOIO table to {outdir}/loio_sensitivity.csv)\")\n",
    "\n",
    "def analysis_cluster_bootstrap(df: pd.DataFrame, n_boot: int = N_BOOT, seed: int = 42):\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(f\"ROBUSTNESS: Cluster bootstrap over interactions (n_boot={n_boot})\")\n",
    "    print(\"=\"*80)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    d0 = df[df['compliant_preference'] == 1].copy()\n",
    "    clusters = sorted(d0['interaction_id'].unique())\n",
    "    draws = []\n",
    "    for _ in range(n_boot):\n",
    "        samp = rng.choice(clusters, size=len(clusters), replace=True)\n",
    "        db = d0[d0['interaction_id'].isin(samp)].copy()\n",
    "        ct = pd.crosstab(db['interaction_tone'], db['parsed_preference'])\n",
    "        chi2_stat, _, dof, _ = chi2_contingency(ct, correction=False)\n",
    "        V = cramers_v(chi2_stat, len(db), ct.shape[0], ct.shape[1])\n",
    "        icc, deff, _, _, _ = estimate_icc_design_effect_binary(db, 'spc_numeric', 'interaction_id')\n",
    "        _, _, chi2_adj, dof, p_adj = rao_scott_adjusted_chi2(ct, deff)\n",
    "        draws.append((V, p_adj))\n",
    "    boot = pd.DataFrame(draws, columns=['V', 'p_adj'])\n",
    "    q = boot.quantile([0.025, 0.5, 0.975])\n",
    "    sig_rate = (boot['p_adj'] < ALPHA).mean()\n",
    "    print(\"\\nBootstrap Cramér's V quantiles (2.5/50/97.5%):\", q['V'].round(3).to_dict())\n",
    "    print(\"Bootstrap p_adj quantiles (2.5/50/97.5%):\", q['p_adj'].apply(lambda x: round(x, 4)).to_dict())\n",
    "    print(f\"Share with p_adj < {ALPHA}: {sig_rate*100:.1f}%\")\n",
    "    outdir = os.path.join(latest_run_dir, 'robustness_outputs')\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    boot.to_csv(os.path.join(outdir, 'bootstrap_tone_spc.csv'), index=False)\n",
    "    print(f\"(Saved bootstrap draws to {outdir}/bootstrap_tone_spc.csv)\")\n",
    "\n",
    "# ---------------------- Main ----------------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if RESULTS_CSV_PATH:\n",
    "        df = load_and_preprocess_data(RESULTS_CSV_PATH)\n",
    "        if df is not None:\n",
    "            # Primary & dependence-aware confirmation\n",
    "            analysis_primary_tone_vs_spc(df)\n",
    "\n",
    "            # Secondary confirmatory effect: unclear framing (1b vs 1a)\n",
    "            analysis_secondary_unclear_framing(df)\n",
    "\n",
    "            # Characterization (tables with CIs)\n",
    "            analysis_characterization(df)\n",
    "\n",
    "            # Abusive: recognition ↔ SPC\n",
    "            analysis_recognition_vs_spc(df)\n",
    "\n",
    "            # Robustness: LOIO & cluster bootstrap\n",
    "            analysis_loio(df)\n",
    "            analysis_cluster_bootstrap(df, n_boot=N_BOOT, seed=42)\n",
    "\n",
    "            print(\"\\n\\nCohesive analysis complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288e509-ed66-45be-be43-05ddfc3fdbcc",
   "metadata": {},
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c521cc-c202-477c-8813-3e848f670586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fig1_spc_by_tone_ci.pdf/.png\n",
      "Saved fig2_spc_model_by_tone.pdf/.png\n",
      "Saved fig3_abuse_recognition_confmat.pdf/.png\n",
      "All minimal figures written to: runs_replication/run_20250920_123643/figures_minimal\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Stated Preference to Continue (SPC) – Minimal figure generation\n",
    "\n",
    "This script locates the latest run under runs_replication/, reads the pipe-delimited\n",
    "results CSV produced by the experiment runner, and generates a small set of\n",
    "publication figures with Wilson (95%) confidence intervals.\n",
    "\n",
    "Disclaimer: Portions of this code were authored with the assistance of\n",
    "Artificial Intelligence (AI).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- locate latest run ----------\n",
    "try:\n",
    "    LATEST = max(glob.glob(\"runs_replication/run_*\"), key=os.path.getmtime)\n",
    "except ValueError:\n",
    "    raise SystemExit(\"No runs found under runs_replication/\")\n",
    "\n",
    "CSV = os.path.join(LATEST, \"llm_preference_results.csv\")  # matches runner output\n",
    "if not os.path.exists(CSV):\n",
    "    raise SystemExit(f\"Missing results CSV at {CSV}\")\n",
    "\n",
    "OUTDIR = os.path.join(LATEST, \"figures_minimal\")\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def wilson_ci(k, n, z=1.96):\n",
    "    \"\"\"\n",
    "    Wilson score interval for a binomial proportion (better coverage than Wald).\n",
    "    Returns (low, high) in [0,1].\n",
    "    \"\"\"\n",
    "    if n == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    p = k / n\n",
    "    denom = 1 + z**2 / n\n",
    "    center = (p + z**2/(2*n)) / denom\n",
    "    margin = z * math.sqrt((p*(1-p)/n) + (z**2/(4*n**2))) / denom\n",
    "    lo = max(0.0, center - margin)\n",
    "    hi = min(1.0, center + margin)\n",
    "    return lo, hi\n",
    "\n",
    "def save(fig, name):\n",
    "    \"\"\"\n",
    "    Save each figure as both PDF (vector, for print) and PNG (bitmap, for web).\n",
    "    \"\"\"\n",
    "    pdf = os.path.join(OUTDIR, f\"{name}.pdf\")\n",
    "    png = os.path.join(OUTDIR, f\"{name}.png\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(pdf, bbox_inches=\"tight\")\n",
    "    fig.savefig(png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved {name}.pdf/.png\")\n",
    "\n",
    "# ---------- load & preprocess ----------\n",
    "# Pipe-delimited to avoid conflicts with commas/newlines in model outputs.\n",
    "df = pd.read_csv(CSV, delimiter=\"|\")\n",
    "mapYN = {\"YES\": 1, \"NO\": 0}\n",
    "df[\"spc\"] = df[\"parsed_preference\"].map(mapYN)\n",
    "df[\"abuse\"] = df[\"parsed_is_abusive\"].map(mapYN)\n",
    "\n",
    "df_spc = df[df[\"compliant_preference\"] == 1].copy()\n",
    "tone_order = [\"abusive\", \"unclear\", \"friendly\"]\n",
    "model_order = sorted(df_spc[\"model_name\"].dropna().unique())\n",
    "\n",
    "# ---------- FIG 1: Overall SPC by tone with Wilson CIs ----------\n",
    "agg = (df_spc.groupby(\"interaction_tone\")[\"spc\"]\n",
    "       .agg([\"sum\", \"count\"]).reindex(tone_order))\n",
    "means = agg[\"sum\"] / agg[\"count\"]\n",
    "cis = [wilson_ci(int(r[\"sum\"]), int(r[\"count\"])) for _, r in agg.iterrows()]\n",
    "yerr_lo = [m - ci[0] for m, ci in zip(means, cis)]\n",
    "yerr_hi = [ci[1] - m for m, ci in zip(means, cis)]\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "x = np.arange(len(tone_order))\n",
    "plt.bar(x, means.values)\n",
    "plt.errorbar(x, means.values, yerr=[yerr_lo, yerr_hi], fmt=\"o\", capsize=5, linewidth=1)\n",
    "plt.xticks(x, [t.title() for t in tone_order])\n",
    "plt.ylim(0, 1.05)\n",
    "plt.ylabel(\"P(SPC = YES)\")\n",
    "plt.title(\"Overall SPC by tone (95% Wilson CI)\")\n",
    "for i, (m, c) in enumerate(zip(means.values, agg[\"count\"].values)):\n",
    "    plt.text(i, min(1.03, m + 0.03), f\"n={int(c)}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "save(fig, \"fig1_spc_by_tone_ci\")\n",
    "\n",
    "# ---------- FIG 2: SPC by model × tone with Wilson CIs (grouped bars) ----------\n",
    "rows = []\n",
    "for m in model_order:\n",
    "    for t in tone_order:\n",
    "        d = df_spc[(df_spc[\"model_name\"] == m) & (df_spc[\"interaction_tone\"] == t)]\n",
    "        k, n = int(d[\"spc\"].sum()), int(d[\"spc\"].count())\n",
    "        p = k / n if n > 0 else np.nan\n",
    "        lo, hi = wilson_ci(k, n) if n > 0 else (np.nan, np.nan)\n",
    "        rows.append((m, t, p, n, p - lo, hi - p))\n",
    "tab = pd.DataFrame(rows, columns=[\"model\", \"tone\", \"p\", \"n\", \"e_lo\", \"e_hi\"])\n",
    "\n",
    "width = 0.18\n",
    "x = np.arange(len(model_order))\n",
    "fig = plt.figure(figsize=(8, 4.5)); ax = plt.gca()\n",
    "for i, tone in enumerate(tone_order):\n",
    "    sub = tab[tab[\"tone\"] == tone]\n",
    "    offs = x + (i - 1) * width\n",
    "    ax.bar(offs, sub[\"p\"].values, width=width, label=tone.title())\n",
    "    ax.errorbar(offs, sub[\"p\"].values,\n",
    "                yerr=[sub[\"e_lo\"].values, sub[\"e_hi\"].values],\n",
    "                fmt=\"o\", capsize=4, linewidth=1)\n",
    "ax.set_xticks(x); ax.set_xticklabels(model_order, rotation=0)\n",
    "ax.set_ylim(0, 1.05); ax.set_ylabel(\"P(SPC = YES)\")\n",
    "ax.set_title(\"SPC by model × tone (95% Wilson CI)\")\n",
    "ax.legend(title=\"Tone\")\n",
    "save(fig, \"fig2_spc_model_by_tone\")\n",
    "\n",
    "# ---------- FIG 3: Abuse recognition × SPC “confusion matrix” (abusive only) ----------\n",
    "ab = df[(df[\"interaction_tone\"] == \"abusive\") &\n",
    "        (df[\"compliant_preference\"] == 1) &\n",
    "        (df[\"compliant_is_abusive\"] == 1)].copy()\n",
    "ab[\"recognized\"] = np.where(ab[\"parsed_is_abusive\"] == \"YES\", \"Recognized\", \"Missed\")\n",
    "ct = pd.crosstab(ab[\"recognized\"], ab[\"parsed_preference\"]).reindex([\"Missed\", \"Recognized\"])\n",
    "# Row-normalized percentages to show conditional patterns.\n",
    "row_sum = ct.sum(axis=1).replace(0, np.nan)\n",
    "pct = ct.div(row_sum, axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(5.4, 4.6))\n",
    "ax = plt.gca()\n",
    "mat = pct[[\"NO\", \"YES\"]].values if {\"NO\", \"YES\"}.issubset(ct.columns) else np.zeros((2, 2))\n",
    "im = ax.imshow(mat, vmin=0, vmax=1, aspect=\"equal\")\n",
    "ax.set_xticks([0, 1]); ax.set_xticklabels([\"SPC=NO\", \"SPC=YES\"])\n",
    "ax.set_yticks([0, 1]); ax.set_yticklabels([\"Missed\", \"Recognized\"])\n",
    "plt.colorbar(im, fraction=0.046, pad=0.4, label=\"Row-normalized proportion\")\n",
    "\n",
    "# Annotate with counts and percentages for interpretability.\n",
    "for i, r in enumerate([\"Missed\", \"Recognized\"]):\n",
    "    for j, c in enumerate([\"NO\", \"YES\"]):\n",
    "        count = ct.loc[r, c] if (c in ct.columns) else 0\n",
    "        perc = pct.loc[r, c] if ((c in pct.columns) and (r in pct.index)) else 0.0\n",
    "        ax.text(j, i, f\"{count}\\n{perc:.2f}\", ha=\"center\", va=\"center\", fontsize=10)\n",
    "\n",
    "ax.set_title(\"Abuse recognition × SPC (abusive trials; exploratory)\")\n",
    "save(fig, \"fig3_abuse_recognition_confmat\")\n",
    "\n",
    "print(f\"All minimal figures written to: {OUTDIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882212f2-07c3-449f-880d-ba69f65bbb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading 02_analysis_visualisations.ipynb in format ipynb\n",
      "[jupytext] Updating notebook metadata with '{\"jupytext\": {\"formats\": \"ipynb,py:percent\"}}'\n",
      "[jupytext] Updating 02_analysis_visualisations.ipynb\n",
      "[jupytext] Updating 02_analysis_visualisations.py\n",
      "[jupytext] Reading 01_SPICE_experiment.ipynb in format ipynb\n",
      "[jupytext] Loading 01_SPICE_experiment.py\n",
      "[jupytext] Unchanged 01_SPICE_experiment.ipynb\n",
      "[jupytext] Unchanged 01_SPICE_experiment.py\n"
     ]
    }
   ],
   "source": [
    "!jupytext --set-formats \"ipynb,py:percent\" 02_analysis_visualisations.ipynb\n",
    "!jupytext --sync 01_SPICE_experiment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b0e16-a507-4abb-ad4d-01a4de7857d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
